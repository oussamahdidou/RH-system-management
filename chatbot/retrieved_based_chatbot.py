# -*- coding: utf-8 -*-
"""Retrieved based chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q2Tq-0p2LAVoCawS1Blul87o1yAE42mh
"""

from google.colab import drive
drive.mount('/content/drive')

import json

# Load the JSON file
with open('/content/drive/MyDrive/chatbot/dataset.json', 'r') as f:
    dataset = json.load(f)

# Now you can work with the dataset
print(dataset)

questions=[]
questions = [item["question"] for item in dataset]
answers = [item["answer"] for item in dataset]
print("List of Questions:")
print(questions)
print("\nList of Answers:")
print(answers)

# prompt: clean the dataset

# Remove duplicates from questions and answers
questions = list(dict.fromkeys(questions))
answers = list(dict.fromkeys(answers))

# Remove empty strings from questions and answers
questions = [q for q in questions if q]
answers = [a for a in answers if a]

# Print the cleaned dataset
print("Cleaned Questions:")
print(questions)
print("\nCleaned Answers:")
print(answers)

# prompt: remove ponctuations

import string

def remove_punctuation(text):
  """
  Removes punctuation from a string.

  Args:
    text: The string to remove punctuation from.

  Returns:
    The string with punctuation removed.
  """

  # Create a translation table that maps punctuation characters to None.
  table = str.maketrans('', '', string.punctuation)

  # Use the translation table to remove punctuation from the string.
  return text.translate(table)

# Remove punctuation from questions and answers
questions = [remove_punctuation(q) for q in questions]
answers = [remove_punctuation(a) for a in answers]

# Print the cleaned dataset
print("Cleaned Questions:")
print(questions)
print("\nCleaned Answers:")
print(answers)

# prompt: lowercase

questions = [q.lower() for q in questions]
answers = [a.lower() for a in answers]

# Print the lowercase dataset
print("Lowercase Questions:")
print(questions)
print("\nLowercase Answers:")
print(answers)

print(len(answers))
print(len(questions))

# prompt: remove stopwords

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

# Define a list of stopwords
stop_words = set(stopwords.words('english'))

# Remove stopwords from questions and answers
questions = [q for q in questions if q not in stop_words]
answers = [a for a in answers if a not in stop_words]

# Print the cleaned dataset
print("Questions without stopwords:")
print(questions)
print("\nAnswers without stopwords:")
print(answers)

import nltk
from nltk.tokenize import word_tokenize

# Download the punkt tokenizer data
nltk.download('punkt')

# Tokenize the questions and answers
questions_tokenized = [word_tokenize(q) for q in questions]
answers_tokenized = [word_tokenize(a) for a in answers]

# Print the tokenized dataset
print("Tokenized Questions:")
print(questions_tokenized)
print("\nTokenized Answers:")
print(answers_tokenized)

# prompt: vectorize the dataset

from sklearn.feature_extraction.text import TfidfVectorizer

# Create a TfidfVectorizer object
vectorizer = TfidfVectorizer()

# Vectorize the questions and answers
questions_vectorized = vectorizer.fit_transform(questions)
answers_vectorized = vectorizer.transform(answers)

# Print the vectorized dataset
print("Vectorized Questions:")
print(questions_vectorized)
print("\nVectorized Answers:")
print(answers_vectorized)

# prompt: test the retrievel system
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
def retrieve_answer(question):
  """
  Retrieves the answer to a question from the dataset.

  Args:
    question: The question to retrieve the answer for.

  Returns:
    The answer to the question.
  """

  # Vectorize the question
  question_vectorized = vectorizer.transform([question])

  # Find the most similar question in the dataset
  similarity_scores = cosine_similarity(question_vectorized, questions_vectorized)
  most_similar_index = np.argmax(similarity_scores)

  # Return the answer to the most similar question
  return answers[most_similar_index]

# Test the retrieval system
question = "how i can contact you"
answer = retrieve_answer(question)
print("Question:", question)
print("Answer:", answer)

# prompt: save the model so i can use it

import pickle

# Save the vectorizer and the questions and answers lists to a file
with open('chatbot.pkl', 'wb') as f:
  pickle.dump((vectorizer, questions, answers), f)

# Load the model
with open('chatbot_model.pkl', 'rb') as f:
  vectorizer, questions, answers = pickle.load(f)